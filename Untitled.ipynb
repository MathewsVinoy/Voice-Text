{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81e21bc-0d07-468b-b59f-812581d683f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "libtorch_cuda.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mT\u001b[39;00m\n\u001b[1;32m      4\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/cv-corpus-16.1-delta-2023-12-06/en/clips/common_voice_en_38991191.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torchaudio/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dropping_io_support, dropping_class_io_support\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize extension and backend first\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa  # usort: skip\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa  # usort: skip\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     AudioMetaData \u001b[38;5;28;01mas\u001b[39;00m _AudioMetaData,\n\u001b[1;32m      7\u001b[0m     get_audio_backend \u001b[38;5;28;01mas\u001b[39;00m _get_audio_backend,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     set_audio_backend \u001b[38;5;28;01mas\u001b[39;00m _set_audio_backend,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchcodec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_with_torchcodec, save_with_torchcodec\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torchaudio/_extension/__init__.py:38\u001b[0m\n\u001b[1;32m     36\u001b[0m _IS_ALIGN_AVAILABLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_TORCHAUDIO_EXT_AVAILABLE:\n\u001b[0;32m---> 38\u001b[0m     _load_lib(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibtorchaudio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchaudio\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     _check_cuda_version()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torchaudio/_extension/utils.py:60\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mload_library(path)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/_ops.py:1478\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1473\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1478\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mCDLL(path)\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/ctypes/__init__.py:390\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m _dlopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, mode)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: libtorch_cuda.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "    import torchaudio\n",
    "    import torchaudio.transforms as T\n",
    "\n",
    "    audio_path = \"data/cv-corpus-16.1-delta-2023-12-06/en/clips/common_voice_en_38991191.mp3\"\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b39bf7b0-d8fa-4bc1-97e3-76386e383f77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_mfcc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m  \u001b[38;5;66;03m# Number of MFCC coefficients\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mfcc_transform \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mMFCC(\n\u001b[1;32m      3\u001b[0m     sample_rate\u001b[38;5;241m=\u001b[39msample_rate,\n\u001b[1;32m      4\u001b[0m     n_mfcc\u001b[38;5;241m=\u001b[39mn_mfcc,\n\u001b[1;32m      5\u001b[0m     melkwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_fft\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2048\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhop_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m512\u001b[39m} \u001b[38;5;66;03m# Example MelSpectrogram arguments\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m mfccs \u001b[38;5;241m=\u001b[39m mfcc_transform(waveform)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "n_mfcc = 40  # Number of MFCC coefficients\n",
    "mfcc_transform = T.MFCC(\n",
    "    sample_rate=sample_rate,\n",
    "    n_mfcc=n_mfcc,\n",
    "    melkwargs={\"n_fft\": 2048, \"hop_length\": 512} # Example MelSpectrogram arguments\n",
    ")\n",
    "mfccs = mfcc_transform(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53378104-b900-4e48-9fec-d56e01cd1484",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mfccs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mfccs\u001b[38;5;241m.\u001b[39msize()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mfccs' is not defined"
     ]
    }
   ],
   "source": [
    "mfccs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a708fb2-c2f8-4c62-8e89-e87a0913baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31627a0-5f18-4fd9-8435-5d5d2f901756",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCHS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e6d56ad-6862-4180-b1e8-732f1dd4acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = Path(\"data/cv-corpus-16.1-delta-2023-12-06/en/invalidated.tsv\")\n",
    "audio_path = \"data/train\"\n",
    "data = pd.read_csv(csv_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09cad231-db82-46c5-b8e5-f5ba9a8d4307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>372293e65cdab88771e028a4351651ab2eff64438ddafc...</td>\n",
       "      <td>common_voice_en_38491552.mp3</td>\n",
       "      <td>This above all is what made the Chicago rivalr...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>fifties</td>\n",
       "      <td>male</td>\n",
       "      <td>German English,Non native speaker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  372293e65cdab88771e028a4351651ab2eff64438ddafc...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_en_38491552.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  This above all is what made the Chicago rivalr...         0           2   \n",
       "\n",
       "       age gender                            accents  variant locale  segment  \n",
       "0  fifties   male  German English,Non native speaker      NaN     en      NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b076b526-bc38-4fde-9b94-eced6d658513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    common_voice_en_38491552.mp3\n",
       "1    common_voice_en_38491622.mp3\n",
       "2    common_voice_en_38492275.mp3\n",
       "3    common_voice_en_38492276.mp3\n",
       "4    common_voice_en_38492281.mp3\n",
       "Name: path, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['path'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c94f545-87e9-40c4-8171-58b47577c049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This above all is what made the Chicago rivalr...\n",
       "1    Many episodes and scenes were borrowed from va...\n",
       "2    Once upon a time, Cricket Was My Reason For Li...\n",
       "3    After his death, Hutton petitioned to have gun...\n",
       "4                     She was named for the clamagore.\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentence'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1477b226-db7e-49cb-af0b-a63f6d22974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/mathews/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "all_tokens = []\n",
    "for text in data['sentence'].astype(str).fillna(''):\n",
    "    tokens = word_tokenize(text)\n",
    "    all_tokens.extend(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a76513cb-8869-4969-a29c-187ec6c0ae16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5490"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(set(all_tokens))\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9442a029-1a05-42c1-b0c6-1f8598322b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2991, 3366,  682, ..., 1737, 4924, 3122])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(tokens)\n",
    "integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02a3d358-b452-4d5a-b6cb-ab48910cbcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['escaped', 'harvest', 'Gouin', ..., 'Tunisia', 'stay', 'fetus'],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_tokens = label_encoder.inverse_transform(integer_encoded)\n",
    "decoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74434cb5-6000-4572-a829-5d331b77f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_num = {char: idx for idx, char in enumerate(set(tokens))}\n",
    "num_to_words = {idx: char for idx, char in enumerate(set(tokens))}\n",
    "\n",
    "encode = lambda s: [words_to_num[c] for c in word_tokenize(s)]\n",
    "def encode2(l):\n",
    "\n",
    "    l=str(l)\n",
    "    value = [words_to_num[c] for c in word_tokenize(l)]\n",
    "    while len(value) <82:\n",
    "        value.append(0)\n",
    "    return torch.tensor(value, dtype=torch.float32)\n",
    "\n",
    "    \n",
    "def decoder(l):\n",
    "    return ' '.join([num_to_words.get(i,'<UNK>') for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae173f55-0790-43e4-9b95-baa47dedf923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['path'], data['sentence'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaa0077a-0a16-4d62-bc92-6bc7651a43b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('common_voice_en_38491552.mp3',\n",
       " 'This above all is what made the Chicago rivalry unique in Major League Baseball.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0],y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "062282c2-b4b4-459c-ade0-329e40f47d53",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "libtorch_cuda.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mT\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Fallback for MP3\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torchaudio/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dropping_io_support, dropping_class_io_support\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize extension and backend first\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa  # usort: skip\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa  # usort: skip\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     AudioMetaData \u001b[38;5;28;01mas\u001b[39;00m _AudioMetaData,\n\u001b[1;32m      7\u001b[0m     get_audio_backend \u001b[38;5;28;01mas\u001b[39;00m _get_audio_backend,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     set_audio_backend \u001b[38;5;28;01mas\u001b[39;00m _set_audio_backend,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchcodec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_with_torchcodec, save_with_torchcodec\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torchaudio/_extension/__init__.py:38\u001b[0m\n\u001b[1;32m     36\u001b[0m _IS_ALIGN_AVAILABLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_TORCHAUDIO_EXT_AVAILABLE:\n\u001b[0;32m---> 38\u001b[0m     _load_lib(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibtorchaudio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchaudio\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     _check_cuda_version()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torchaudio/_extension/utils.py:60\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mload_library(path)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/torch/_ops.py:1478\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1473\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1478\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mCDLL(path)\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/ctypes/__init__.py:390\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m _dlopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, mode)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: libtorch_cuda.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "# Fallback for MP3\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DatasetsCustom(Dataset):\n",
    "    def __init__(self, X, y, path, sample_rate=16000, n_mfcc=40):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (list or pd.Series): list of audio file names\n",
    "            y (list or pd.Series): list of labels (same length as X)\n",
    "            path (str): directory containing audio files\n",
    "        \"\"\"\n",
    "        self.X = X.reset_index(drop=True)\n",
    "        self.y = y.reset_index(drop=True)\n",
    "        self.audio_path = path\n",
    "        self.sample_rate = sample_rate\n",
    "        self.mfcc_transform = T.MFCC(\n",
    "            sample_rate=sample_rate,\n",
    "            n_mfcc=n_mfcc,\n",
    "            melkwargs={\"n_fft\": 2048, \"hop_length\": 512}\n",
    "        )\n",
    "\n",
    "    def load_audio(self, file_name):\n",
    "        audio_path = os.path.join(self.audio_path, file_name)\n",
    "\n",
    "        try:\n",
    "            # Try with torchaudio\n",
    "            waveform, sr = torchaudio.load(audio_path)\n",
    "        except Exception as e:\n",
    "            # If torchaudio fails (e.g. MP3 not supported), fallback to pydub\n",
    "            audio = AudioSegment.from_file(audio_path, format=\"mp3\")\n",
    "            samples = np.array(audio.get_array_of_samples()).astype(np.float32)\n",
    "\n",
    "            # stereo -> mono\n",
    "            if audio.channels > 1:\n",
    "                samples = samples.reshape((-1, audio.channels))\n",
    "                samples = samples.mean(axis=1)\n",
    "\n",
    "            waveform = torch.tensor(samples).unsqueeze(0)  # shape (1, time)\n",
    "            sr = audio.frame_rate\n",
    "\n",
    "        # Resample if needed\n",
    "        if sr != self.sample_rate:\n",
    "            resampler = T.Resample(sr, self.sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # Convert to MFCC -> (n_mfcc, time)\n",
    "        mfcc = self.mfcc_transform(waveform)\n",
    "\n",
    "        # Change shape to (time, n_mfcc) for RNN input\n",
    "        mfcc = mfcc.squeeze(0).transpose(0, 1)\n",
    "        return mfcc\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.X.iloc[idx]\n",
    "        label = self.y.iloc[idx]\n",
    "        mfcc = self.load_audio(file_name)\n",
    "        return mfcc, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ea247b8-d11d-4116-9a38-c4bfe4c9b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = DatasetsCustom(X=X_train, y=y_train, path=audio_path)\n",
    "test_datasets  = DatasetsCustom(X=X_test, y=y_test, path=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3612489b-c354-4ac5-b789-1e2fb8a3579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_datasets, batch_size=32, num_workers=0, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_datasets, batch_size=32, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5db1fde7-626c-4d24-af1e-00cef30d0f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AudioModel(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int, num_layers: int = 2, bidirectional: bool = True, dropout: float = 0.3):\n",
    "        super(AudioModel, self).__init__()\n",
    "\n",
    "        # LSTM backbone\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_shape,   # n_mfcc from your dataset (e.g., 40)\n",
    "            hidden_size=hidden_units,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Fully connected classifier\n",
    "        rnn_out = hidden_units * (2 if bidirectional else 1)\n",
    "        self.fc = nn.Linear(rnn_out, output_shape)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: [B, T, F] where\n",
    "           B = batch size\n",
    "           T = time steps\n",
    "           F = n_mfcc (input_shape)n_mfcc = 40                 # must match dataset MFCC config\n",
    "hidden_units = 128\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "model = AudioModel(input_shape=n_mfcc, hidden_units=hidden_units, output_shape=num_classes).to(device)\n",
    "\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # LSTM forward\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # Take the last timestep output\n",
    "        lstm_out_last = lstm_out[:, -1, :]   # [B, hidden*dir]\n",
    "\n",
    "        # Classification\n",
    "        output = self.fc(lstm_out_last)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e507966-98b1-4890-b332-79751e159d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 40                 # must match dataset MFCC config\n",
    "hidden_units = 128\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "model = AudioModel(input_shape=n_mfcc, hidden_units=hidden_units, output_shape=num_classes).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bace0ac-1b98-49ca-8d68-ace55a1bdce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "LibsndfileError",
     "evalue": "Error opening 'data/train/common_voice_en_38991191.mp3': System error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader):\n\u001b[1;32m     10\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     12\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[17], line 45\u001b[0m, in \u001b[0;36mDatasetsCustom.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     42\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[idx]\n\u001b[1;32m     43\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[idx]\n\u001b[0;32m---> 45\u001b[0m mfcc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_audio(file_name)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mfcc, label\n",
      "Cell \u001b[0;32mIn[17], line 26\u001b[0m, in \u001b[0;36mDatasetsCustom.load_audio\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_audio\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_name):\n\u001b[1;32m     25\u001b[0m     audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m     waveform, sr \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(audio_path)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Resample if needed\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_rate:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torchaudio/_backend/utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mload(uri, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m, buffer_size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torchaudio/_backend/soundfile.py:27\u001b[0m, in \u001b[0;36mSoundfileBackend.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     19\u001b[0m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     buffer_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m,\n\u001b[1;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m soundfile_backend\u001b[38;5;241m.\u001b[39mload(uri, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torchaudio/_backend/soundfile_backend.py:221\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;129m@_requires_soundfile\u001b[39m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m    141\u001b[0m     filepath: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mformat\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from file.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m soundfile\u001b[38;5;241m.\u001b[39mSoundFile(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWAV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m normalize:\n\u001b[1;32m    223\u001b[0m             dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/soundfile.py:690\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bitrate_mode \u001b[38;5;241m=\u001b[39m bitrate_mode\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/soundfile.py:1265\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ptr \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'data/train/common_voice_en_38991191.mp3': System error."
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        inputs, labels = batch\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, labels)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_dataloader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, train loss {train_loss / len(train_dataloader)}, test loss {test_loss / len(test_dataloader)}\")\n",
    "        \n",
    "    MODEL_PATH = Path(\"models\")\n",
    "    MODEL_NAME = \"model_train.pth\"\n",
    "    MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "    \n",
    "    \n",
    "    MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    #Save\n",
    "    torch.save(obj=model.state_dict(),f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15630a-da04-43b1-82c9-267abba7b690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2ee39-2505-4a7f-ad7e-257007f65857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481402b0-9265-4862-9f8a-7734365fc35e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
